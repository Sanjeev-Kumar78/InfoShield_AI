{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adc28b50",
   "metadata": {},
   "source": [
    "## üì¶ Installation\n",
    "\n",
    "First, let's install the required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffbc250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Google ADK and dependencies\n",
    "!pip install -q google-adk python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296364b9",
   "metadata": {},
   "source": [
    "## üîë API Key Setup\n",
    "\n",
    "You need a Google AI Studio API key. Get one free at: https://aistudio.google.com/apikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5195fdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# Get API key from Kaggle Secrets\n",
    "# Go to Add-ons > Secrets > Add new secret named GOOGLE_API_KEY\n",
    "try:\n",
    "    user_secrets = UserSecretsClient()\n",
    "    os.environ['GOOGLE_API_KEY'] = user_secrets.get_secret('GOOGLE_API_KEY')\n",
    "    print(\"‚úÖ API Key loaded from Kaggle Secrets!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to load API key: {e}\")\n",
    "    print(\"Please add GOOGLE_API_KEY in Add-ons > Secrets\")\n",
    "\n",
    "# Use Google AI Studio (not Vertex AI)\n",
    "os.environ['GOOGLE_GENAI_USE_VERTEXAI'] = 'False'\n",
    "\n",
    "print(\"‚úÖ Environment configured!\" if os.environ.get('GOOGLE_API_KEY') else \"‚ùå API Key missing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc799a7",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Architecture\n",
    "\n",
    "InfoShield uses a **Sequential Multi-Agent** architecture:\n",
    "\n",
    "```\n",
    "User Query ‚Üí Analyzer Agent ‚Üí Search Agent ‚Üí Credibility Agent ‚Üí Synthesizer ‚Üí Response\n",
    "```\n",
    "\n",
    "Each agent has a specific role:\n",
    "- **Analyzer**: Extracts sentiment, urgency, location, disaster type\n",
    "- **Search**: Finds real-time news and official sources\n",
    "- **Credibility**: Scores the reliability of information\n",
    "- **Synthesizer**: Creates the final verification report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137a121d",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b20f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration constants\n",
    "MODEL_ID = \"gemini-2.5-pro\"\n",
    "MODEL_ID_FAST = \"gemini-2.5-flash\"\n",
    "\n",
    "URGENCY_THRESHOLD = 8      # Score >= 8 triggers immediate response\n",
    "CREDIBILITY_THRESHOLD = 60 # Score >= 60% enables automated response\n",
    "\n",
    "# Disaster Keywords for Detection\n",
    "DISASTER_KEYWORDS = [\n",
    "    \"flood\", \"flooding\", \"earthquake\", \"tsunami\", \"cyclone\", \"hurricane\",\n",
    "    \"tornado\", \"wildfire\", \"fire\", \"landslide\", \"avalanche\", \"drought\",\n",
    "    \"volcano\", \"eruption\", \"storm\", \"typhoon\", \"blizzard\", \"heatwave\",\n",
    "    \"rescue\", \"emergency\", \"evacuation\", \"trapped\", \"help\", \"sos\"\n",
    "]\n",
    "\n",
    "# Official Sources for Credibility Scoring\n",
    "OFFICIAL_SOURCES = [\n",
    "    # Global\n",
    "    \"un ocha\", \"red cross\", \"red crescent\", \"who\", \"unicef\",\n",
    "    # News\n",
    "    \"reuters\", \"ap news\", \"afp\", \"bbc\", \"cnn\", \"al jazeera\",\n",
    "    # Weather\n",
    "    \"accuweather\", \"weather.com\",\n",
    "    # India\n",
    "    \"ndrf\", \"ndma\", \"imd\", \"india met\",\n",
    "    # USA\n",
    "    \"fema\", \"nws\", \"noaa\", \"usgs\",\n",
    "    # UK\n",
    "    \"met office\", \"bbc weather\",\n",
    "    # Japan\n",
    "    \"jma\", \"japan meteorological agency\"\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ Configuration loaded!\")\n",
    "print(f\"   Model: {MODEL_ID}\")\n",
    "print(f\"   Urgency Threshold: {URGENCY_THRESHOLD}\")\n",
    "print(f\"   Credibility Threshold: {CREDIBILITY_THRESHOLD}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9b9a48",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Tools Implementation\n",
    "\n",
    "### Tool 1: Query Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f99808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Dict, Any\n",
    "\n",
    "\n",
    "def analyze_query(query: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Analyze a disaster-related query for sentiment, urgency, and location.\n",
    "\n",
    "    Args:\n",
    "        query: The user's disaster-related query string.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with sentiment, urgency_score, location, disaster_type,\n",
    "        is_emergency, and keywords_found.\n",
    "    \"\"\"\n",
    "    query_lower = query.lower()\n",
    "\n",
    "    # Detect disaster keywords\n",
    "    keywords_found = [kw for kw in DISASTER_KEYWORDS if kw in query_lower]\n",
    "\n",
    "    # Urgency indicators\n",
    "    panic_indicators = [\"help\", \"sos\", \"emergency\", \"trapped\", \"dying\", \"drowning\"]\n",
    "    urgent_indicators = [\"now\", \"immediately\", \"urgent\", \"quickly\", \"asap\", \"!\"]\n",
    "\n",
    "    # Calculate urgency score\n",
    "    urgency_score = 3  # Base score\n",
    "    if any(ind in query_lower for ind in panic_indicators):\n",
    "        urgency_score += 4\n",
    "    if any(ind in query_lower for ind in urgent_indicators):\n",
    "        urgency_score += 2\n",
    "    if query.count(\"!\") >= 2:\n",
    "        urgency_score += 1\n",
    "    if len(keywords_found) > 0:\n",
    "        urgency_score += len(keywords_found)\n",
    "    urgency_score = min(10, max(1, urgency_score))\n",
    "\n",
    "    # Determine sentiment\n",
    "    if urgency_score >= 8:\n",
    "        sentiment = \"panic\"\n",
    "    elif urgency_score >= 6:\n",
    "        sentiment = \"urgent\"\n",
    "    elif urgency_score >= 4:\n",
    "        sentiment = \"concerned\"\n",
    "    elif \"?\" in query and len(keywords_found) == 0:\n",
    "        sentiment = \"curious\"\n",
    "    else:\n",
    "        sentiment = \"neutral\"\n",
    "\n",
    "    # Extract location\n",
    "    location = \"Unknown\"\n",
    "    location_patterns = [\n",
    "        r\"in\\s+([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*)\",\n",
    "        r\"at\\s+([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*)\",\n",
    "        r\"near\\s+([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*)\",\n",
    "        r\"from\\s+([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*)\",\n",
    "    ]\n",
    "    for pattern in location_patterns:\n",
    "        match = re.search(pattern, query)\n",
    "        if match:\n",
    "            location = match.group(1)\n",
    "            break\n",
    "\n",
    "    # Identify disaster type\n",
    "    disaster_type = None\n",
    "    disaster_mapping = {\n",
    "        \"flood\": [\"flood\", \"flooding\", \"water entering\"],\n",
    "        \"earthquake\": [\"earthquake\", \"quake\", \"tremor\", \"seismic\"],\n",
    "        \"tsunami\": [\"tsunami\", \"tidal wave\"],\n",
    "        \"cyclone\": [\"cyclone\", \"hurricane\", \"typhoon\", \"storm\"],\n",
    "        \"fire\": [\"fire\", \"wildfire\", \"blaze\", \"burning\"],\n",
    "        \"landslide\": [\"landslide\", \"mudslide\", \"debris\"],\n",
    "    }\n",
    "    for dtype, keywords in disaster_mapping.items():\n",
    "        if any(kw in query_lower for kw in keywords):\n",
    "            disaster_type = dtype\n",
    "            break\n",
    "\n",
    "    is_emergency = urgency_score >= 8 or any(ind in query_lower for ind in panic_indicators)\n",
    "\n",
    "    return {\n",
    "        \"sentiment\": sentiment,\n",
    "        \"urgency_score\": urgency_score,\n",
    "        \"location\": location,\n",
    "        \"disaster_type\": disaster_type,\n",
    "        \"is_emergency\": is_emergency,\n",
    "        \"keywords_found\": keywords_found\n",
    "    }\n",
    "\n",
    "\n",
    "# Test the analyzer\n",
    "test_query = \"Help! There's flooding in Mumbai, water is entering houses!\"\n",
    "result = analyze_query(test_query)\n",
    "print(f\"Query: {test_query}\")\n",
    "print(f\"Analysis: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf649e6e",
   "metadata": {},
   "source": [
    "### Tool 2: Credibility Scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f40d4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_credibility(\n",
    "    search_summary: str,\n",
    "    sources_mentioned: str = \"\",\n",
    "    location: str = \"\",\n",
    "    disaster_type: str = \"\"\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Calculate credibility score based on search results and sources.\n",
    "\n",
    "    Args:\n",
    "        search_summary: Summary of search results.\n",
    "        sources_mentioned: Comma-separated list of sources.\n",
    "        location: Location from the query.\n",
    "        disaster_type: Type of disaster identified.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with score, reasoning, sources_found, etc.\n",
    "    \"\"\"\n",
    "    search_lower = search_summary.lower()\n",
    "    sources_lower = sources_mentioned.lower()\n",
    "\n",
    "    score = 0\n",
    "    reasons = []\n",
    "    sources_found = []\n",
    "    official_count = 0\n",
    "    news_count = 0\n",
    "\n",
    "    # Check for official sources\n",
    "    for source in OFFICIAL_SOURCES:\n",
    "        if source in search_lower or source in sources_lower:\n",
    "            sources_found.append(source)\n",
    "            if source in [\"ndrf\", \"ndma\", \"fema\", \"government\", \"ministry\", \"official\"]:\n",
    "                official_count += 1\n",
    "            else:\n",
    "                news_count += 1\n",
    "\n",
    "    # Score official sources (max 40)\n",
    "    if official_count > 0:\n",
    "        official_points = min(40, official_count * 20)\n",
    "        score += official_points\n",
    "        reasons.append(f\"Found {official_count} official source(s) (+{official_points})\")\n",
    "\n",
    "    # Score news sources (max 30)\n",
    "    if news_count > 0:\n",
    "        news_points = min(30, news_count * 10)\n",
    "        score += news_points\n",
    "        reasons.append(f\"Found {news_count} news source(s) (+{news_points})\")\n",
    "\n",
    "    # Recency indicators (+10)\n",
    "    recency_keywords = [\"today\", \"now\", \"just\", \"breaking\", \"latest\", \"current\"]\n",
    "    if any(kw in search_lower for kw in recency_keywords):\n",
    "        score += 10\n",
    "        reasons.append(\"Recent/current event indicators (+10)\")\n",
    "\n",
    "    # Location specificity (+10)\n",
    "    if location and location.lower() != \"unknown\":\n",
    "        if location.lower() in search_lower:\n",
    "            score += 10\n",
    "            reasons.append(f\"Location '{location}' confirmed (+10)\")\n",
    "\n",
    "    # Multiple source corroboration (+10)\n",
    "    if len(sources_found) >= 3:\n",
    "        score += 10\n",
    "        reasons.append(\"Multiple sources corroborate (+10)\")\n",
    "\n",
    "    # Clamp score to 0-100\n",
    "    score = min(100, max(0, score))\n",
    "\n",
    "    # Determine status\n",
    "    if score >= 70:\n",
    "        status = \"Verified\"\n",
    "    elif score >= 50:\n",
    "        status = \"Partially Verified\"\n",
    "    elif score >= 30:\n",
    "        status = \"Unverified\"\n",
    "    else:\n",
    "        status = \"Likely Misinformation\"\n",
    "\n",
    "    return {\n",
    "        \"score\": score,\n",
    "        \"status\": status,\n",
    "        \"reasoning\": \"; \".join(reasons) if reasons else \"No credible sources found\",\n",
    "        \"sources_found\": sources_found,\n",
    "        \"official_sources_count\": official_count,\n",
    "        \"news_sources_count\": news_count\n",
    "    }\n",
    "\n",
    "\n",
    "# Test the credibility scorer\n",
    "test_summary = \"NDRF confirms flooding in Chennai. Reuters reports heavy rain. BBC coverage ongoing.\"\n",
    "result = calculate_credibility(test_summary, \"ndrf.gov.in, reuters.com\", \"Chennai\", \"flood\")\n",
    "print(f\"Credibility Score: {result['score']}/100\")\n",
    "print(f\"Status: {result['status']}\")\n",
    "print(f\"Reasoning: {result['reasoning']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8f7ed5",
   "metadata": {},
   "source": [
    "### Tool 3: Human Review Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaefb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from datetime import datetime\n",
    "\n",
    "# In-memory storage for Kaggle (no file system persistence)\n",
    "HUMAN_REVIEW_QUEUE = []\n",
    "\n",
    "\n",
    "def save_for_human_review(\n",
    "    query: str,\n",
    "    location: str,\n",
    "    urgency_score: int,\n",
    "    credibility_score: int\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Save a query for human expert verification.\n",
    "\n",
    "    Args:\n",
    "        query: The original user query.\n",
    "        location: Extracted location.\n",
    "        urgency_score: Urgency score (1-10).\n",
    "        credibility_score: Credibility score (0-100).\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with session_id, status, and estimated_review_time.\n",
    "    \"\"\"\n",
    "    session_id = str(uuid.uuid4())[:8].upper()\n",
    "    timestamp = datetime.now().isoformat()\n",
    "\n",
    "    entry = {\n",
    "        \"session_id\": session_id,\n",
    "        \"timestamp\": timestamp,\n",
    "        \"query\": query,\n",
    "        \"location\": location,\n",
    "        \"urgency_score\": urgency_score,\n",
    "        \"credibility_score\": credibility_score,\n",
    "        \"status\": \"pending\"\n",
    "    }\n",
    "\n",
    "    HUMAN_REVIEW_QUEUE.append(entry)\n",
    "\n",
    "    # Estimate review time based on urgency\n",
    "    if urgency_score >= 8:\n",
    "        review_time = \"15-30 minutes (Priority)\"\n",
    "    elif urgency_score >= 5:\n",
    "        review_time = \"1-2 hours\"\n",
    "    else:\n",
    "        review_time = \"4-8 hours\"\n",
    "\n",
    "    return {\n",
    "        \"session_id\": session_id,\n",
    "        \"status\": \"saved\",\n",
    "        \"message\": f\"Query saved for human review with ID: {session_id}\",\n",
    "        \"estimated_review_time\": review_time\n",
    "    }\n",
    "\n",
    "\n",
    "# Test\n",
    "result = save_for_human_review(\n",
    "    \"Aliens attacking downtown!\",\n",
    "    \"Unknown\",\n",
    "    5,\n",
    "    15\n",
    ")\n",
    "print(f\"Human Review: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739798f9",
   "metadata": {},
   "source": [
    "## ü§ñ Agent Definitions\n",
    "\n",
    "Now let's create the multi-agent system using Google ADK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00cd2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from google.adk.agents import Agent, SequentialAgent\n",
    "from google.adk.tools import google_search, FunctionTool\n",
    "\n",
    "CURRENT_DATE = datetime.now().strftime(\"%B %d, %Y\")\n",
    "\n",
    "# ============== ANALYZER AGENT ==============\n",
    "ANALYZER_INSTRUCTION = \"\"\"You are the Analyzer Agent for InfoShield AI.\n",
    "Your job is to analyze disaster-related queries using the `analyze_query` tool.\n",
    "\n",
    "## YOUR ROLE\n",
    "1. Receive a query.\n",
    "2. Call the `analyze_query` tool with the query string.\n",
    "3. Return the analysis results as JSON.\n",
    "\n",
    "## OUTPUT FORMAT\n",
    "Return ONLY the tool output as a JSON string.\n",
    "\"\"\"\n",
    "\n",
    "def create_analyzer_agent():\n",
    "    analysis_tool = FunctionTool(analyze_query)\n",
    "    return Agent(\n",
    "        name=\"analyzer_agent\",\n",
    "        model=MODEL_ID_FAST,\n",
    "        description=\"Analyzes disaster queries for urgency, sentiment, and location.\",\n",
    "        instruction=ANALYZER_INSTRUCTION,\n",
    "        tools=[analysis_tool],\n",
    "        output_key=\"analysis_result\"\n",
    "    )\n",
    "\n",
    "\n",
    "# ============== SEARCH AGENT ==============\n",
    "SEARCH_INSTRUCTION = f\"\"\"You are the Search Agent for InfoShield AI.\n",
    "Your job is to search for CURRENT, REAL-TIME disaster information.\n",
    "\n",
    "**Today's date: {CURRENT_DATE}**\n",
    "\n",
    "## YOUR ROLE\n",
    "You have access to analysis results in {{analysis_result}}.\n",
    "Extract location and disaster_type, then perform targeted searches.\n",
    "\n",
    "## SEARCH STRATEGY\n",
    "1. \"[location] [disaster_type] news today {CURRENT_DATE}\"\n",
    "2. \"[location] disaster alert warning official\"\n",
    "3. \"[location] weather conditions current\"\n",
    "\n",
    "## OUTPUT FORMAT\n",
    "Return search findings with source names and dates.\n",
    "\"\"\"\n",
    "\n",
    "def create_search_agent():\n",
    "    return Agent(\n",
    "        name=\"search_agent\",\n",
    "        model=MODEL_ID,\n",
    "        description=\"Searches for real-time disaster information.\",\n",
    "        instruction=SEARCH_INSTRUCTION,\n",
    "        tools=[google_search],\n",
    "        output_key=\"search_result\"\n",
    "    )\n",
    "\n",
    "\n",
    "# ============== CREDIBILITY AGENT ==============\n",
    "CREDIBILITY_INSTRUCTION = \"\"\"You are the Credibility Agent for InfoShield AI.\n",
    "Your job is to evaluate the trustworthiness of disaster reports.\n",
    "\n",
    "## YOUR ROLE\n",
    "1. Access search results in {search_result}.\n",
    "2. Call `calculate_credibility` with appropriate parameters.\n",
    "3. Return the credibility assessment as JSON.\n",
    "\"\"\"\n",
    "\n",
    "def create_credibility_agent():\n",
    "    credibility_tool = FunctionTool(calculate_credibility)\n",
    "    return Agent(\n",
    "        name=\"credibility_agent\",\n",
    "        model=MODEL_ID,\n",
    "        description=\"Evaluates credibility of disaster reports.\",\n",
    "        instruction=CREDIBILITY_INSTRUCTION,\n",
    "        tools=[credibility_tool],\n",
    "        output_key=\"credibility_result\"\n",
    "    )\n",
    "\n",
    "\n",
    "# ============== SYNTHESIZER AGENT ==============\n",
    "SYNTHESIZER_INSTRUCTION = f\"\"\"You are the InfoShield AI Report Synthesizer.\n",
    "\n",
    "**Today's Date: {CURRENT_DATE}**\n",
    "\n",
    "## YOUR ROLE\n",
    "Create a comprehensive verification report using data from:\n",
    "- {{analysis_result}}: Sentiment, urgency, location, disaster_type\n",
    "- {{search_result}}: Search findings with sources\n",
    "- {{credibility_result}}: Credibility score and status\n",
    "\n",
    "## FINAL RESPONSE FORMAT\n",
    "\n",
    "**üìä INFOSHIELD VERIFICATION REPORT**\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| Status | [status] |\n",
    "| Credibility Score | [score]/100 |\n",
    "| Urgency Level | [Low/Medium/High/Critical] |\n",
    "| Location | [location] |\n",
    "| Disaster Type | [type] |\n",
    "\n",
    "**üìã Summary:**\n",
    "[Bullet point summary of findings]\n",
    "\n",
    "**üõ°Ô∏è Safety Advice:**\n",
    "[Appropriate safety advice]\n",
    "\n",
    "**üì∞ Sources:**\n",
    "[List of sources]\n",
    "\n",
    "**‚ö†Ô∏è Disclaimer:**\n",
    "For emergencies, contact local emergency services (911, 112) directly.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ============== ORCHESTRATOR ==============\n",
    "def create_orchestrator():\n",
    "    \"\"\"Create the sequential multi-agent orchestrator.\"\"\"\n",
    "    analyzer = create_analyzer_agent()\n",
    "    searcher = create_search_agent()\n",
    "    credibility = create_credibility_agent()\n",
    "\n",
    "    synthesizer = Agent(\n",
    "        name=\"synthesizer_agent\",\n",
    "        model=MODEL_ID,\n",
    "        description=\"Creates the final verification report.\",\n",
    "        instruction=SYNTHESIZER_INSTRUCTION,\n",
    "    )\n",
    "\n",
    "    return SequentialAgent(\n",
    "        name=\"infoshield_orchestrator\",\n",
    "        description=\"InfoShield AI multi-agent disaster verification system\",\n",
    "        sub_agents=[analyzer, searcher, credibility, synthesizer]\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"‚úÖ Agents defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac38a84",
   "metadata": {},
   "source": [
    "## üöÄ Running InfoShield AI\n",
    "\n",
    "Now let's create a runner and test the system!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdeff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.genai import types\n",
    "\n",
    "\n",
    "async def run_infoshield(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Process a disaster query through InfoShield AI.\n",
    "\n",
    "    Args:\n",
    "        query: The user's disaster-related query.\n",
    "\n",
    "    Returns:\n",
    "        The verification report as a string.\n",
    "    \"\"\"\n",
    "    print(f\"\\nüîç Processing: {query}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Create orchestrator and runner\n",
    "    orchestrator = create_orchestrator()\n",
    "    session_service = InMemorySessionService()\n",
    "\n",
    "    runner = Runner(\n",
    "        agent=orchestrator,\n",
    "        app_name=\"infoshield_ai\",\n",
    "        session_service=session_service\n",
    "    )\n",
    "\n",
    "    # Create session\n",
    "    session = await session_service.create_session(\n",
    "        app_name=\"infoshield_ai\",\n",
    "        user_id=\"kaggle_user\"\n",
    "    )\n",
    "\n",
    "    # Run the query\n",
    "    content = types.Content(\n",
    "        role=\"user\",\n",
    "        parts=[types.Part(text=query)]\n",
    "    )\n",
    "\n",
    "    final_response = \"\"\n",
    "    async for event in runner.run_async(\n",
    "        user_id=\"kaggle_user\",\n",
    "        session_id=session.id,\n",
    "        new_message=content\n",
    "    ):\n",
    "        if event.is_final_response():\n",
    "            if event.content and event.content.parts:\n",
    "                final_response = event.content.parts[0].text\n",
    "\n",
    "    return final_response\n",
    "\n",
    "\n",
    "# Helper for Jupyter notebooks\n",
    "def process_query(query: str) -> str:\n",
    "    \"\"\"Sync wrapper for run_infoshield.\"\"\"\n",
    "    return asyncio.get_event_loop().run_until_complete(run_infoshield(query))\n",
    "\n",
    "\n",
    "print(\"‚úÖ Runner ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54565437",
   "metadata": {},
   "source": [
    "## üß™ Test Queries\n",
    "\n",
    "Let's test with different types of queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7713cbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Query 1: High Urgency Emergency\n",
    "query1 = \"Help! There's flooding in Chennai, water is entering houses! Need immediate help!\"\n",
    "\n",
    "response = await run_infoshield(query1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7a07f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Query 2: Information Request\n",
    "query2 = \"Is there a tsunami warning for the coast of Japan?\"\n",
    "\n",
    "response = await run_infoshield(query2)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a1d3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Query 3: General Preparedness\n",
    "query3 = \"What should I do to prepare for an earthquake?\"\n",
    "\n",
    "response = await run_infoshield(query3)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6a1464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Query 4: Low Credibility (should trigger human review)\n",
    "query4 = \"Aliens are attacking the city center!\"\n",
    "\n",
    "response = await run_infoshield(query4)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08282f6f",
   "metadata": {},
   "source": [
    "## üìä Interactive Mode\n",
    "\n",
    "Try your own queries!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2ff509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive mode - enter your own query\n",
    "user_query = input(\"Enter your disaster query: \")\n",
    "\n",
    "if user_query.strip():\n",
    "    response = await run_infoshield(user_query)\n",
    "    print(response)\n",
    "else:\n",
    "    print(\"No query entered.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb72e011",
   "metadata": {},
   "source": [
    "## üìù Human Review Queue\n",
    "\n",
    "Check queries flagged for human expert review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c579ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display pending human reviews\n",
    "if HUMAN_REVIEW_QUEUE:\n",
    "    print(f\"üìã Pending Human Reviews ({len(HUMAN_REVIEW_QUEUE)}):\")\n",
    "    print(\"-\" * 60)\n",
    "    for entry in HUMAN_REVIEW_QUEUE:\n",
    "        print(f\"  ID: {entry['session_id']}\")\n",
    "        print(f\"  Query: {entry['query'][:50]}...\")\n",
    "        print(f\"  Credibility: {entry['credibility_score']}/100\")\n",
    "        print(f\"  Status: {entry['status']}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"‚úÖ No pending human reviews.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b785246b",
   "metadata": {},
   "source": [
    "## üéØ Summary\n",
    "\n",
    "InfoShield AI demonstrates a **multi-agent architecture** using Google ADK:\n",
    "\n",
    "1. **Analyzer Agent**: Extracts intent, urgency, and location\n",
    "2. **Search Agent**: Performs real-time web searches\n",
    "3. **Credibility Agent**: Scores information reliability\n",
    "4. **Synthesizer Agent**: Creates the final report\n",
    "\n",
    "### Key Features Demonstrated:\n",
    "- ‚úÖ Sequential agent orchestration with `SequentialAgent`\n",
    "- ‚úÖ State sharing between agents via `output_key`\n",
    "- ‚úÖ Built-in `google_search` tool integration\n",
    "- ‚úÖ Custom `FunctionTool` for business logic\n",
    "- ‚úÖ Human-in-the-loop for low-confidence queries\n",
    "\n",
    "---\n",
    "\n",
    "**‚ö†Ô∏è Disclaimer:** This AI system is for informational purposes only. For life-threatening emergencies, always contact local emergency services (911, 112, etc.) directly."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
